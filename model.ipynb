{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from optuna) (23.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from optuna)\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /home/codespace/.local/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /home/codespace/.local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /home/codespace/.local/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: tqdm, Mako, greenlet, colorlog, cmaes, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 greenlet-2.0.2 optuna-3.1.1 sqlalchemy-2.0.11 tqdm-4.65.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting meteostat\n",
      "  Downloading meteostat-1.6.5-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: pandas>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from meteostat) (2.0.1)\n",
      "Requirement already satisfied: pytz in /home/codespace/.local/lib/python3.10/site-packages (from meteostat) (2023.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from meteostat) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.1->meteostat) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.1->meteostat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.16.0)\n",
      "Installing collected packages: meteostat\n",
      "Successfully installed meteostat-1.6.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install meteostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.10.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import gc\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error,r2_score,mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit,cross_val_score,KFold\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import os\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting importnb\n",
      "  Downloading importnb-2023.1.7-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: importnb\n",
      "Successfully installed importnb-2023.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install importnb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with the new api\n",
    "from importnb import imports\n",
    "with imports(\"ipynb\"):\n",
    "    import modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    target = 'tüketim'\n",
    "    train_path = 'data/train.csv'\n",
    "    test_path = 'data/sample_submission.csv'\n",
    "    med_path = 'data/med.csv'\n",
    "    submission_path='data/sample_submission.csv'\n",
    "    generation_path='data/TR_enerji_uretimi.csv'\n",
    "    weatherfrom_wwo='data/izmir_weather_data.csv'\n",
    "    meteostat_feature_columns = ['temp','dwpt','rhum','prcp','wdir','wspd','pres','coco']\n",
    "    production_features = True\n",
    "    consumption_features = False\n",
    "    yuk_tahmin_plani_features = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(CFG.train_path).rename(columns={'Dağıtılan Enerji (MWh)':'tüketim'})\n",
    "test=pd.read_csv(CFG.test_path).rename(columns={'Dağıtılan Enerji (MWh)':'tüketim'})\n",
    "med=pd.read_csv(CFG.med_path)\n",
    "submission=pd.read_csv(CFG.submission_path)\n",
    "train = modules.timeseries_features(train.set_index('Tarih'))\n",
    "test= modules.timeseries_features(test.set_index('Tarih'))\n",
    "test['tüketim']=test['tüketim'].replace(0,np.nan)\n",
    "train.index=pd.to_datetime(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.concat([train,test],axis=0)\n",
    "all_data.index=pd.to_datetime(all_data.index)\n",
    "med.Tarih=pd.to_datetime(med.Tarih)\n",
    "# Gün içindeki elektrik kesinti süresinin kabul edilebilir limiti aştığı gün.\n",
    "med['Tarih']=med['Tarih'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2018/17220.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2019/17220.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2020/17220.csv.gz from https://bulk.meteostat.net/v2/\n",
      "InsecureRequestWarning: Unverified HTTPS request is being made to host 'seffaflik.epias.com.tr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n"
     ]
    }
   ],
   "source": [
    "weather=modules.get_meteostat_data(datetime(2018, 1, 1), datetime(2022, 9, 1),features=CFG.meteostat_feature_columns)[:-1]\n",
    "generation=pd.read_csv(CFG.generation_path).iloc[:,1:]\n",
    "generation.Tarih=pd.to_datetime(generation.Tarih)\n",
    "generation=generation[['total','Tarih']]\n",
    "# generation=real_time_generation()\n",
    "consumption=modules.real_time_consumption()\n",
    "con_pro=consumption.merge(generation,on='Tarih',how='left')\n",
    "con_pro.set_index('Tarih',drop=True,inplace=True)\n",
    "all_data=all_data.merge(weather,left_index=True,right_index=True)\n",
    "all_data=all_data.merge(con_pro,left_index=True,right_index=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "yuk=pd.read_csv('data/YukTahmin.csv',encoding='unicode_escape').iloc[:40896,2]\n",
    "all_data['yuk']=yuk.values\n",
    "all_data.yuk=all_data.yuk.str.replace(',','').astype(float)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "ep=pd.read_csv('data/DENGESIZLIK.csv',encoding='unicode_escape').iloc[:40896,2:]\n",
    "all_data['pozitif']=ep['Pozitif Dengesizlik Miktarý (MWh)'].values\n",
    "all_data['pozitif']=all_data['pozitif'].str.replace(',','').astype(float)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "ue=pd.read_csv('data/UECM.csv',encoding='unicode_escape').iloc[:40896,2:]\n",
    "ue['UEÇM (MWh)']=ue['UEÇM (MWh)'].str.replace(',','').astype(float)\n",
    "all_data['ue']=ue['UEÇM (MWh)'].values\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "weatherfrom_wwo=pd.read_csv(CFG.weatherfrom_wwo,index_col='date_time')[:'2022-08-31 23:00:00']\n",
    "weatherfrom_wwo.index=pd.to_datetime(weatherfrom_wwo.index)\n",
    "all_data=all_data.merge(weatherfrom_wwo[['pressure','humidity','uvIndex','WindGustKmph','windspeedKmph']],left_index=True,right_index=True)\n",
    "all_index=all_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tüketim', 'hour', 'date', 'dayofweek', 'quarter', 'month', 'year',\n",
       "       'dayofyear', 'dayofmonth', 'weekday', 'wntr_month', 'month_label',\n",
       "       'season', 'weekend', 'working_hours', 'label_hour', 'prime_time',\n",
       "       'temp', 'dwpt', 'rhum', 'prcp', 'wdir', 'wspd', 'pres', 'coco',\n",
       "       'consumption', 'total', 'yuk', 'pozitif', 'ue', 'pressure', 'humidity',\n",
       "       'uvIndex', 'WindGustKmph', 'windspeedKmph'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "all_data=modules.lag_features(all_data,['pres','rhum','humidity','uvIndex','WindGustKmph','temp','total','yuk','ue','pozitif'],48,24) \n",
    "# all_data=diff_pct_features(all_data,['pres','rhum','humidity','uvIndex','WindGustKmph','temp','total','yuk','ue'],1) \n",
    "all_data=modules.rolling_features(all_data,['pres','rhum','humidity','uvIndex','WindGustKmph','temp','total','yuk','ue','pozitif'],[6,12,18,24,30,36,42,48],['mean',''])\n",
    "all_data=modules.rolling_shift_features(all_data,['pres','rhum','humidity','uvIndex','WindGustKmph','temp','total','yuk','ue','pozitif'],[6,12,18,24,30,36,42,48],['mean','std'],shift=24)\n",
    "\n",
    "# hour_df=seasonality_spline_features()\n",
    "# all_data=all_data.merge(hour_df, on='hour').set_index(all_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Changed some columns of dtypes to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "all_data['med_label']=np.where(all_data.date.isin(med.Tarih),1,0)\n",
    "all_data=modules.is_categorical(all_data,all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40152, 296)\n",
      "(744, 296)\n"
     ]
    }
   ],
   "source": [
    "df_train=all_data[all_data.tüketim.notnull()]\n",
    "df_test=all_data[all_data.tüketim.isnull()]\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding by some of seasonal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=modules.cat_target_encode(df_train,df_test,'tüketim','hour','mean')\n",
    "df_train,df_test=modules.cat_target_encode(df_train,df_test,'tüketim',['season','weekend','hour'],'mean')\n",
    "df_train,df_test=modules.cat_target_encode(df_train,df_test,'tüketim',['season','weekday','prime_time','hour'],'mean')\n",
    "all_data=pd.concat([df_train,df_test])\n",
    "all_data.drop(['pres','rhum','humidity','uvIndex','WindGustKmph','temp','total','yuk','ue','pozitif'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data=all_data.reset_index(drop=True)\n",
    "all_data.drop([\n",
    "'date',\n",
    "'dayofyear',\n",
    "'dayofweek',\n",
    " # 'weekofyear'\n",
    "# 'year'\n",
    "],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features are labeled for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 285)\n",
      "(40152, 286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "cat_features=all_data.select_dtypes('category').columns\n",
    "le_fit={}\n",
    "all_data[cat_features],le_fit=modules.label_data(feature=cat_features,data=all_data,le_fit=le_fit)\n",
    "data_train=all_data[all_data.tüketim.notnull()]\n",
    "test_sub=all_data[all_data.tüketim.isnull()]\n",
    "test_sub.drop('tüketim',axis=1,inplace=True)\n",
    "print(test_sub.shape)\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wntr_month</th>\n",
       "      <th>month_label</th>\n",
       "      <th>season</th>\n",
       "      <th>weekend</th>\n",
       "      <th>working_hours</th>\n",
       "      <th>label_hour</th>\n",
       "      <th>prime_time</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>coco</th>\n",
       "      <th>consumption</th>\n",
       "      <th>pressure</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>lag_24_pres</th>\n",
       "      <th>lag_48_pres</th>\n",
       "      <th>lag_24_rhum</th>\n",
       "      <th>lag_48_rhum</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_shift_24_std_36_ue</th>\n",
       "      <th>rolling_shift_24_mean_42_ue</th>\n",
       "      <th>rolling_shift_24_std_42_ue</th>\n",
       "      <th>rolling_shift_24_mean_48_ue</th>\n",
       "      <th>rolling_shift_24_std_48_ue</th>\n",
       "      <th>rolling_shift_24_mean_6_pozitif</th>\n",
       "      <th>rolling_shift_24_std_6_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_12_pozitif</th>\n",
       "      <th>rolling_shift_24_std_12_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_18_pozitif</th>\n",
       "      <th>rolling_shift_24_std_18_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_24_pozitif</th>\n",
       "      <th>rolling_shift_24_std_24_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_30_pozitif</th>\n",
       "      <th>rolling_shift_24_std_30_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_36_pozitif</th>\n",
       "      <th>rolling_shift_24_std_36_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_42_pozitif</th>\n",
       "      <th>rolling_shift_24_std_42_pozitif</th>\n",
       "      <th>rolling_shift_24_mean_48_pozitif</th>\n",
       "      <th>rolling_shift_24_std_48_pozitif</th>\n",
       "      <th>med_label</th>\n",
       "      <th>hour_te</th>\n",
       "      <th>season_weekend_hour_te</th>\n",
       "      <th>season_weekday_prime_time_hour_te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>39107.65</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>114</td>\n",
       "      <td>121</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>4.118585</td>\n",
       "      <td>41.899277</td>\n",
       "      <td>4.164680</td>\n",
       "      <td>41.092238</td>\n",
       "      <td>4.478351</td>\n",
       "      <td>37113.166667</td>\n",
       "      <td>6140.349613</td>\n",
       "      <td>46006.833333</td>\n",
       "      <td>11890.922335</td>\n",
       "      <td>54600.061793</td>\n",
       "      <td>24990.215814</td>\n",
       "      <td>47601.838011</td>\n",
       "      <td>25469.263374</td>\n",
       "      <td>45368.137076</td>\n",
       "      <td>23280.800376</td>\n",
       "      <td>45286.364230</td>\n",
       "      <td>22357.577412</td>\n",
       "      <td>44696.312197</td>\n",
       "      <td>21164.000848</td>\n",
       "      <td>43590.752339</td>\n",
       "      <td>20162.163078</td>\n",
       "      <td>0</td>\n",
       "      <td>1667.289193</td>\n",
       "      <td>1915.604283</td>\n",
       "      <td>1807.355303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>356</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>37166.97</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>119</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>4.145238</td>\n",
       "      <td>41.901995</td>\n",
       "      <td>4.160798</td>\n",
       "      <td>41.052530</td>\n",
       "      <td>4.514116</td>\n",
       "      <td>35499.666667</td>\n",
       "      <td>8286.338677</td>\n",
       "      <td>44491.750000</td>\n",
       "      <td>13540.135135</td>\n",
       "      <td>51055.172904</td>\n",
       "      <td>24604.636441</td>\n",
       "      <td>47527.379678</td>\n",
       "      <td>25539.938763</td>\n",
       "      <td>45025.803742</td>\n",
       "      <td>23531.822072</td>\n",
       "      <td>43646.642007</td>\n",
       "      <td>21705.386144</td>\n",
       "      <td>44323.407435</td>\n",
       "      <td>21401.068590</td>\n",
       "      <td>43184.752339</td>\n",
       "      <td>20370.293209</td>\n",
       "      <td>0</td>\n",
       "      <td>1523.275694</td>\n",
       "      <td>1769.667279</td>\n",
       "      <td>1671.733959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>36049.11</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>111</td>\n",
       "      <td>118</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>4.114362</td>\n",
       "      <td>41.742032</td>\n",
       "      <td>4.306678</td>\n",
       "      <td>41.017427</td>\n",
       "      <td>4.557577</td>\n",
       "      <td>33561.500000</td>\n",
       "      <td>10012.400327</td>\n",
       "      <td>42375.333333</td>\n",
       "      <td>14967.037469</td>\n",
       "      <td>47246.228459</td>\n",
       "      <td>23419.565690</td>\n",
       "      <td>47817.671345</td>\n",
       "      <td>25190.874539</td>\n",
       "      <td>44765.003742</td>\n",
       "      <td>23749.310774</td>\n",
       "      <td>43391.753119</td>\n",
       "      <td>21909.822946</td>\n",
       "      <td>43435.097911</td>\n",
       "      <td>21540.875231</td>\n",
       "      <td>43173.460672</td>\n",
       "      <td>20382.168019</td>\n",
       "      <td>0</td>\n",
       "      <td>1420.525514</td>\n",
       "      <td>1657.821245</td>\n",
       "      <td>1561.155129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>35100.89</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>109</td>\n",
       "      <td>118</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>4.098883</td>\n",
       "      <td>41.476561</td>\n",
       "      <td>4.455710</td>\n",
       "      <td>40.979346</td>\n",
       "      <td>4.612297</td>\n",
       "      <td>32146.000000</td>\n",
       "      <td>9802.766650</td>\n",
       "      <td>40314.083333</td>\n",
       "      <td>14838.361564</td>\n",
       "      <td>43617.561793</td>\n",
       "      <td>20430.686088</td>\n",
       "      <td>48301.671345</td>\n",
       "      <td>24704.251086</td>\n",
       "      <td>44656.870409</td>\n",
       "      <td>23811.680044</td>\n",
       "      <td>43248.558674</td>\n",
       "      <td>21983.059345</td>\n",
       "      <td>42861.883625</td>\n",
       "      <td>21575.766239</td>\n",
       "      <td>43021.960672</td>\n",
       "      <td>20455.152781</td>\n",
       "      <td>0</td>\n",
       "      <td>1369.097812</td>\n",
       "      <td>1591.400905</td>\n",
       "      <td>1499.191051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>338</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>34377.08</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>110</td>\n",
       "      <td>121</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>4.130049</td>\n",
       "      <td>41.146617</td>\n",
       "      <td>4.596069</td>\n",
       "      <td>40.928966</td>\n",
       "      <td>4.692386</td>\n",
       "      <td>31529.000000</td>\n",
       "      <td>9017.160662</td>\n",
       "      <td>38833.750000</td>\n",
       "      <td>13791.563430</td>\n",
       "      <td>41597.172904</td>\n",
       "      <td>18732.191123</td>\n",
       "      <td>49006.838011</td>\n",
       "      <td>24188.182454</td>\n",
       "      <td>44713.037076</td>\n",
       "      <td>23798.117746</td>\n",
       "      <td>43249.892007</td>\n",
       "      <td>21982.853333</td>\n",
       "      <td>43110.812197</td>\n",
       "      <td>21478.124601</td>\n",
       "      <td>43003.544006</td>\n",
       "      <td>20457.543113</td>\n",
       "      <td>0</td>\n",
       "      <td>1342.892269</td>\n",
       "      <td>1545.806167</td>\n",
       "      <td>1466.378634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>44961.13</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>155</td>\n",
       "      <td>148</td>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>4.681138</td>\n",
       "      <td>38.339567</td>\n",
       "      <td>5.380519</td>\n",
       "      <td>37.991376</td>\n",
       "      <td>5.159010</td>\n",
       "      <td>43522.833333</td>\n",
       "      <td>14259.432786</td>\n",
       "      <td>50340.752990</td>\n",
       "      <td>25133.482083</td>\n",
       "      <td>40426.960039</td>\n",
       "      <td>31065.060183</td>\n",
       "      <td>39453.312846</td>\n",
       "      <td>31679.239288</td>\n",
       "      <td>39742.850277</td>\n",
       "      <td>28646.993147</td>\n",
       "      <td>42148.125231</td>\n",
       "      <td>27677.960575</td>\n",
       "      <td>46273.345436</td>\n",
       "      <td>27960.445587</td>\n",
       "      <td>46603.468923</td>\n",
       "      <td>26537.960996</td>\n",
       "      <td>0</td>\n",
       "      <td>2119.241383</td>\n",
       "      <td>2292.534818</td>\n",
       "      <td>2344.213467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>45255.05</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>154</td>\n",
       "      <td>151</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>4.669925</td>\n",
       "      <td>38.567923</td>\n",
       "      <td>5.272747</td>\n",
       "      <td>38.048411</td>\n",
       "      <td>5.174865</td>\n",
       "      <td>36728.166667</td>\n",
       "      <td>14076.135129</td>\n",
       "      <td>44673.836323</td>\n",
       "      <td>23466.029385</td>\n",
       "      <td>41541.345831</td>\n",
       "      <td>29866.222621</td>\n",
       "      <td>38880.354513</td>\n",
       "      <td>31909.241391</td>\n",
       "      <td>38604.916944</td>\n",
       "      <td>28730.899351</td>\n",
       "      <td>41092.819675</td>\n",
       "      <td>27778.369948</td>\n",
       "      <td>45358.393055</td>\n",
       "      <td>28178.883772</td>\n",
       "      <td>46362.135590</td>\n",
       "      <td>26728.880307</td>\n",
       "      <td>0</td>\n",
       "      <td>2101.625539</td>\n",
       "      <td>2284.982010</td>\n",
       "      <td>2335.804114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>43948.17</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>152</td>\n",
       "      <td>145</td>\n",
       "      <td>76</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>4.663447</td>\n",
       "      <td>38.789207</td>\n",
       "      <td>5.121098</td>\n",
       "      <td>38.105539</td>\n",
       "      <td>5.179381</td>\n",
       "      <td>34062.333333</td>\n",
       "      <td>14486.225135</td>\n",
       "      <td>46804.333333</td>\n",
       "      <td>19936.589867</td>\n",
       "      <td>42961.677813</td>\n",
       "      <td>28343.606555</td>\n",
       "      <td>38459.437846</td>\n",
       "      <td>32019.880572</td>\n",
       "      <td>38038.016944</td>\n",
       "      <td>28817.538444</td>\n",
       "      <td>40751.847453</td>\n",
       "      <td>27894.506426</td>\n",
       "      <td>44520.940674</td>\n",
       "      <td>28233.209476</td>\n",
       "      <td>46064.864756</td>\n",
       "      <td>26881.916114</td>\n",
       "      <td>0</td>\n",
       "      <td>2040.558442</td>\n",
       "      <td>2279.977796</td>\n",
       "      <td>2333.846530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>42775.07</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>151</td>\n",
       "      <td>146</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>4.629922</td>\n",
       "      <td>38.998880</td>\n",
       "      <td>4.937046</td>\n",
       "      <td>38.153208</td>\n",
       "      <td>5.176695</td>\n",
       "      <td>26927.333333</td>\n",
       "      <td>7673.505110</td>\n",
       "      <td>41371.083333</td>\n",
       "      <td>17927.319358</td>\n",
       "      <td>43956.396641</td>\n",
       "      <td>27031.008964</td>\n",
       "      <td>37015.271180</td>\n",
       "      <td>32137.386590</td>\n",
       "      <td>37693.016944</td>\n",
       "      <td>29000.062210</td>\n",
       "      <td>40074.764120</td>\n",
       "      <td>28150.976963</td>\n",
       "      <td>43390.821626</td>\n",
       "      <td>28328.072693</td>\n",
       "      <td>45581.781423</td>\n",
       "      <td>27179.845822</td>\n",
       "      <td>0</td>\n",
       "      <td>1941.787663</td>\n",
       "      <td>2174.866918</td>\n",
       "      <td>2228.278368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>41604.68</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>4.567954</td>\n",
       "      <td>39.184199</td>\n",
       "      <td>4.719843</td>\n",
       "      <td>38.198050</td>\n",
       "      <td>5.160809</td>\n",
       "      <td>26384.166667</td>\n",
       "      <td>7469.502967</td>\n",
       "      <td>37491.666667</td>\n",
       "      <td>15041.338156</td>\n",
       "      <td>43175.229974</td>\n",
       "      <td>27309.229580</td>\n",
       "      <td>34109.021180</td>\n",
       "      <td>29509.602033</td>\n",
       "      <td>37700.850277</td>\n",
       "      <td>28997.150855</td>\n",
       "      <td>39894.736342</td>\n",
       "      <td>28212.400849</td>\n",
       "      <td>42474.178769</td>\n",
       "      <td>28204.728130</td>\n",
       "      <td>44687.343923</td>\n",
       "      <td>27054.266121</td>\n",
       "      <td>0</td>\n",
       "      <td>1825.277281</td>\n",
       "      <td>2052.487703</td>\n",
       "      <td>2102.041946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hour  quarter  month  year  dayofmonth  weekday  wntr_month  month_label   \n",
       "0       0        2      8  2022           1        0           0            1  \\\n",
       "1       1        2      8  2022           1        0           0            1   \n",
       "2       2        2      8  2022           1        0           0            1   \n",
       "3       3        2      8  2022           1        0           0            1   \n",
       "4       4        2      8  2022           1        0           0            1   \n",
       "..    ...      ...    ...   ...         ...      ...         ...          ...   \n",
       "739    19        2      8  2022          31        2           0            1   \n",
       "740    20        2      8  2022          31        2           0            1   \n",
       "741    21        2      8  2022          31        2           0            1   \n",
       "742    22        2      8  2022          31        2           0            1   \n",
       "743    23        2      8  2022          31        2           0            1   \n",
       "\n",
       "     season  weekend  working_hours  label_hour  prime_time  dwpt  prcp  wdir   \n",
       "0         3        0              0           2           0   289     0     5  \\\n",
       "1         3        0              0           0           0   281     0   356   \n",
       "2         3        0              0           1           0   271     0   346   \n",
       "3         3        0              0           0           0   262     0   336   \n",
       "4         3        0              0           1           0   264     0   338   \n",
       "..      ...      ...            ...         ...         ...   ...   ...   ...   \n",
       "739       3        1              0           0           0   315     0   315   \n",
       "740       3        1              0           1           1   318     0   326   \n",
       "741       3        1              0           0           1   318     0   326   \n",
       "742       3        1              0           1           0   318     0   334   \n",
       "743       3        1              0           0           0   315     0   343   \n",
       "\n",
       "     wspd  coco  consumption  pressure  windspeedKmph  lag_24_pres   \n",
       "0      43     1     39107.65        14             15          114  \\\n",
       "1      38     1     37166.97        14             16          111   \n",
       "2      30     1     36049.11        14             17          111   \n",
       "3      30     1     35100.89        14             18          109   \n",
       "4      33     1     34377.08        14             18          110   \n",
       "..    ...   ...          ...       ...            ...          ...   \n",
       "739    21     1     44961.13        17             10          155   \n",
       "740    15     1     45255.05        17             13          154   \n",
       "741    12     1     43948.17        18              8          152   \n",
       "742    11     1     42775.07        18              7          151   \n",
       "743    11     1     41604.68        18             11          147   \n",
       "\n",
       "     lag_48_pres  lag_24_rhum  lag_48_rhum  ...  rolling_shift_24_std_36_ue   \n",
       "0            121           54           49  ...                    4.118585  \\\n",
       "1            119           58           52  ...                    4.145238   \n",
       "2            118           63           55  ...                    4.114362   \n",
       "3            118           69           56  ...                    4.098883   \n",
       "4            121           65           55  ...                    4.130049   \n",
       "..           ...          ...          ...  ...                         ...   \n",
       "739          148           70           56  ...                    4.681138   \n",
       "740          151           74           62  ...                    4.669925   \n",
       "741          145           76           61  ...                    4.663447   \n",
       "742          146           81           64  ...                    4.629922   \n",
       "743          145           79           61  ...                    4.567954   \n",
       "\n",
       "     rolling_shift_24_mean_42_ue  rolling_shift_24_std_42_ue   \n",
       "0                      41.899277                    4.164680  \\\n",
       "1                      41.901995                    4.160798   \n",
       "2                      41.742032                    4.306678   \n",
       "3                      41.476561                    4.455710   \n",
       "4                      41.146617                    4.596069   \n",
       "..                           ...                         ...   \n",
       "739                    38.339567                    5.380519   \n",
       "740                    38.567923                    5.272747   \n",
       "741                    38.789207                    5.121098   \n",
       "742                    38.998880                    4.937046   \n",
       "743                    39.184199                    4.719843   \n",
       "\n",
       "     rolling_shift_24_mean_48_ue  rolling_shift_24_std_48_ue   \n",
       "0                      41.092238                    4.478351  \\\n",
       "1                      41.052530                    4.514116   \n",
       "2                      41.017427                    4.557577   \n",
       "3                      40.979346                    4.612297   \n",
       "4                      40.928966                    4.692386   \n",
       "..                           ...                         ...   \n",
       "739                    37.991376                    5.159010   \n",
       "740                    38.048411                    5.174865   \n",
       "741                    38.105539                    5.179381   \n",
       "742                    38.153208                    5.176695   \n",
       "743                    38.198050                    5.160809   \n",
       "\n",
       "     rolling_shift_24_mean_6_pozitif  rolling_shift_24_std_6_pozitif   \n",
       "0                       37113.166667                     6140.349613  \\\n",
       "1                       35499.666667                     8286.338677   \n",
       "2                       33561.500000                    10012.400327   \n",
       "3                       32146.000000                     9802.766650   \n",
       "4                       31529.000000                     9017.160662   \n",
       "..                               ...                             ...   \n",
       "739                     43522.833333                    14259.432786   \n",
       "740                     36728.166667                    14076.135129   \n",
       "741                     34062.333333                    14486.225135   \n",
       "742                     26927.333333                     7673.505110   \n",
       "743                     26384.166667                     7469.502967   \n",
       "\n",
       "     rolling_shift_24_mean_12_pozitif  rolling_shift_24_std_12_pozitif   \n",
       "0                        46006.833333                     11890.922335  \\\n",
       "1                        44491.750000                     13540.135135   \n",
       "2                        42375.333333                     14967.037469   \n",
       "3                        40314.083333                     14838.361564   \n",
       "4                        38833.750000                     13791.563430   \n",
       "..                                ...                              ...   \n",
       "739                      50340.752990                     25133.482083   \n",
       "740                      44673.836323                     23466.029385   \n",
       "741                      46804.333333                     19936.589867   \n",
       "742                      41371.083333                     17927.319358   \n",
       "743                      37491.666667                     15041.338156   \n",
       "\n",
       "     rolling_shift_24_mean_18_pozitif  rolling_shift_24_std_18_pozitif   \n",
       "0                        54600.061793                     24990.215814  \\\n",
       "1                        51055.172904                     24604.636441   \n",
       "2                        47246.228459                     23419.565690   \n",
       "3                        43617.561793                     20430.686088   \n",
       "4                        41597.172904                     18732.191123   \n",
       "..                                ...                              ...   \n",
       "739                      40426.960039                     31065.060183   \n",
       "740                      41541.345831                     29866.222621   \n",
       "741                      42961.677813                     28343.606555   \n",
       "742                      43956.396641                     27031.008964   \n",
       "743                      43175.229974                     27309.229580   \n",
       "\n",
       "     rolling_shift_24_mean_24_pozitif  rolling_shift_24_std_24_pozitif   \n",
       "0                        47601.838011                     25469.263374  \\\n",
       "1                        47527.379678                     25539.938763   \n",
       "2                        47817.671345                     25190.874539   \n",
       "3                        48301.671345                     24704.251086   \n",
       "4                        49006.838011                     24188.182454   \n",
       "..                                ...                              ...   \n",
       "739                      39453.312846                     31679.239288   \n",
       "740                      38880.354513                     31909.241391   \n",
       "741                      38459.437846                     32019.880572   \n",
       "742                      37015.271180                     32137.386590   \n",
       "743                      34109.021180                     29509.602033   \n",
       "\n",
       "     rolling_shift_24_mean_30_pozitif  rolling_shift_24_std_30_pozitif   \n",
       "0                        45368.137076                     23280.800376  \\\n",
       "1                        45025.803742                     23531.822072   \n",
       "2                        44765.003742                     23749.310774   \n",
       "3                        44656.870409                     23811.680044   \n",
       "4                        44713.037076                     23798.117746   \n",
       "..                                ...                              ...   \n",
       "739                      39742.850277                     28646.993147   \n",
       "740                      38604.916944                     28730.899351   \n",
       "741                      38038.016944                     28817.538444   \n",
       "742                      37693.016944                     29000.062210   \n",
       "743                      37700.850277                     28997.150855   \n",
       "\n",
       "     rolling_shift_24_mean_36_pozitif  rolling_shift_24_std_36_pozitif   \n",
       "0                        45286.364230                     22357.577412  \\\n",
       "1                        43646.642007                     21705.386144   \n",
       "2                        43391.753119                     21909.822946   \n",
       "3                        43248.558674                     21983.059345   \n",
       "4                        43249.892007                     21982.853333   \n",
       "..                                ...                              ...   \n",
       "739                      42148.125231                     27677.960575   \n",
       "740                      41092.819675                     27778.369948   \n",
       "741                      40751.847453                     27894.506426   \n",
       "742                      40074.764120                     28150.976963   \n",
       "743                      39894.736342                     28212.400849   \n",
       "\n",
       "     rolling_shift_24_mean_42_pozitif  rolling_shift_24_std_42_pozitif   \n",
       "0                        44696.312197                     21164.000848  \\\n",
       "1                        44323.407435                     21401.068590   \n",
       "2                        43435.097911                     21540.875231   \n",
       "3                        42861.883625                     21575.766239   \n",
       "4                        43110.812197                     21478.124601   \n",
       "..                                ...                              ...   \n",
       "739                      46273.345436                     27960.445587   \n",
       "740                      45358.393055                     28178.883772   \n",
       "741                      44520.940674                     28233.209476   \n",
       "742                      43390.821626                     28328.072693   \n",
       "743                      42474.178769                     28204.728130   \n",
       "\n",
       "     rolling_shift_24_mean_48_pozitif  rolling_shift_24_std_48_pozitif   \n",
       "0                        43590.752339                     20162.163078  \\\n",
       "1                        43184.752339                     20370.293209   \n",
       "2                        43173.460672                     20382.168019   \n",
       "3                        43021.960672                     20455.152781   \n",
       "4                        43003.544006                     20457.543113   \n",
       "..                                ...                              ...   \n",
       "739                      46603.468923                     26537.960996   \n",
       "740                      46362.135590                     26728.880307   \n",
       "741                      46064.864756                     26881.916114   \n",
       "742                      45581.781423                     27179.845822   \n",
       "743                      44687.343923                     27054.266121   \n",
       "\n",
       "     med_label      hour_te  season_weekend_hour_te   \n",
       "0            0  1667.289193             1915.604283  \\\n",
       "1            0  1523.275694             1769.667279   \n",
       "2            0  1420.525514             1657.821245   \n",
       "3            0  1369.097812             1591.400905   \n",
       "4            0  1342.892269             1545.806167   \n",
       "..         ...          ...                     ...   \n",
       "739          0  2119.241383             2292.534818   \n",
       "740          0  2101.625539             2284.982010   \n",
       "741          0  2040.558442             2279.977796   \n",
       "742          0  1941.787663             2174.866918   \n",
       "743          0  1825.277281             2052.487703   \n",
       "\n",
       "     season_weekday_prime_time_hour_te  \n",
       "0                          1807.355303  \n",
       "1                          1671.733959  \n",
       "2                          1561.155129  \n",
       "3                          1499.191051  \n",
       "4                          1466.378634  \n",
       "..                                 ...  \n",
       "739                        2344.213467  \n",
       "740                        2335.804114  \n",
       "741                        2333.846530  \n",
       "742                        2228.278368  \n",
       "743                        2102.041946  \n",
       "\n",
       "[744 rows x 285 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-30 12:35:27,701]\u001b[0m A new study created in memory with name: no-name-675caa1a-9db3-4474-bcf0-47200b0b8cf6\u001b[0m\n",
      "\u001b[33m[W 2023-04-30 12:35:29,987]\u001b[0m Trial 0 failed with parameters: {'lambda': 5.9627630075645675, 'alpha': 9.324663127256194, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.5, 'max_depth': 5, 'random_state': 24, 'min_child_weight': 312} because of the following error: XGBoostError('[12:35:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\\nStack trace:\\n  [bt] (0) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a7e13) [0x7f14137bbe13]\\n  [bt] (1) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab120) [0x7f14137bf120]\\n  [bt] (2) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab52a) [0x7f14137bf52a]\\n  [bt] (3) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2e03c7) [0x7f14137f43c7]\\n  [bt] (4) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f14136505f0]\\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f1468c02ff5]\\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f1468c0240a]\\n  [bt] (7) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12f51) [0x7f1468ea7f51]\\n  [bt] (8) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xca11) [0x7f1468ea1a11]\\n\\n').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2134/2556684586.py\", line 34, in objective\n",
      "    model.fit(x_train,y_train,eval_set=[(x_train, y_train), (x_val, y_val)],verbose=0)\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [12:35:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a7e13) [0x7f14137bbe13]\n",
      "  [bt] (1) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab120) [0x7f14137bf120]\n",
      "  [bt] (2) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab52a) [0x7f14137bf52a]\n",
      "  [bt] (3) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2e03c7) [0x7f14137f43c7]\n",
      "  [bt] (4) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f14136505f0]\n",
      "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f1468c02ff5]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f1468c0240a]\n",
      "  [bt] (7) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12f51) [0x7f1468ea7f51]\n",
      "  [bt] (8) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xca11) [0x7f1468ea1a11]\n",
      "\n",
      "\n",
      "\u001b[33m[W 2023-04-30 12:35:29,991]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:29] WARNING: ../src/learner.cc:339: No visible GPU is found, setting `gpu_id` to -1\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[12:35:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\nStack trace:\n  [bt] (0) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a7e13) [0x7f14137bbe13]\n  [bt] (1) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab120) [0x7f14137bf120]\n  [bt] (2) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab52a) [0x7f14137bf52a]\n  [bt] (3) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2e03c7) [0x7f14137f43c7]\n  [bt] (4) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f14136505f0]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f1468c02ff5]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f1468c0240a]\n  [bt] (7) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12f51) [0x7f1468ea7f51]\n  [bt] (8) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xca11) [0x7f1468ea1a11]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 54\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m scores\n\u001b[1;32m     53\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m85\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[20], line 34\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, data, target, tscv)\u001b[0m\n\u001b[1;32m     31\u001b[0m     x_val, y_val \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[split_val], target\u001b[38;5;241m.\u001b[39miloc[split_val]\n\u001b[1;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)  \n\u001b[0;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m best_iteration\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbest_iteration\n\u001b[1;32m     36\u001b[0m val_pred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(x_val)\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [12:35:29] ../src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\nStack trace:\n  [bt] (0) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2a7e13) [0x7f14137bbe13]\n  [bt] (1) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab120) [0x7f14137bf120]\n  [bt] (2) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2ab52a) [0x7f14137bf52a]\n  [bt] (3) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x2e03c7) [0x7f14137f43c7]\n  [bt] (4) /usr/local/python/3.10.4/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f14136505f0]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f1468c02ff5]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f1468c0240a]\n  [bt] (7) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12f51) [0x7f1468ea7f51]\n  [bt] (8) /usr/local/python/3.10.4/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xca11) [0x7f1468ea1a11]\n\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3, test_size=2200) \n",
    "target=data_train.tüketim\n",
    "train_labeled=data_train.drop('tüketim',axis=1)\n",
    "def objective(trial,data=train_labeled,target=target,tscv=tscv):\n",
    "    \n",
    "        param = {\n",
    "            'base_score':0.5,\n",
    "            'objective':'reg:squarederror',\n",
    "            'booster':'gbtree', \n",
    "            'lambda': trial.suggest_float('lambda', 1e-3, 10),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-3, 10),\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.7,0.8,0.9,1.0]),\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.5,0.6,0.7,0.8,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', [0.08,0.009,0.01,0.012,0.014,0.016,0.018,0.001,0.1,0.5]),\n",
    "            'n_estimators':1500,\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [3,4,5,7,9,10]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 500),\n",
    "            'tree_method':'hist',\n",
    "            'enable_categorical':True,\n",
    "            'early_stopping_rounds':250\n",
    "        } \n",
    "\n",
    "        best_iteration_list=[]\n",
    "        score_list=[]\n",
    "        model_list=[]\n",
    "        fea_importance_list=[]\n",
    "        tscv_splits = list(tscv.split(data,target))  \n",
    "        for split_train, split_val in tscv_splits:\n",
    "            x_train, y_train = data.iloc[split_train], target.iloc[split_train]\n",
    "            x_val, y_val = data.iloc[split_val], target.iloc[split_val]\n",
    "\n",
    "        model = xgb.XGBRegressor(**param)  \n",
    "        model.fit(x_train,y_train,eval_set=[(x_train, y_train), (x_val, y_val)],verbose=0)\n",
    "        best_iteration=model.best_iteration\n",
    "        val_pred=model.predict(x_val)\n",
    "        model_list.append(model)\n",
    "        score=mean_absolute_percentage_error(y_val, val_pred)\n",
    "        score_list.append(score)\n",
    "        fea_importance_list.append(model.feature_importances_)\n",
    "\n",
    "\n",
    "        trial.set_user_attr('model',model_list)\n",
    "        trial.set_user_attr('best_iteration',best_iteration)\n",
    "        trial.set_user_attr(\"feature_importance\", np.mean(fea_importance_list,axis=0))\n",
    "        trial.set_user_attr(\"score_list\", score_list)\n",
    "\n",
    "        scores=np.mean(score)\n",
    "        return scores\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=85)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEST PARAMS \n",
    "**>params={\n",
    "'lambda': 5.102807684567904, \n",
    "'alpha': 6.511737741485641,\n",
    "'colsample_bytree': 0.9, \n",
    "'subsample': 0.7, \n",
    "'learning_rate': 0.012,\n",
    "'max_depth': 10,\n",
    "'random_state': 24,\n",
    "'min_child_weight': 28,\n",
    "'n_estimators': 1500,\n",
    "'tree_method':'gpu_hist',\n",
    "'enable_categorical':True}**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param={\n",
    "'lambda': 8.48551751148768, 'alpha': 2.366829085730496, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.08, 'max_depth': 5, 'random_state': 48, 'min_child_weight': 24,\n",
    "    'n_estimators': 1500,\n",
    "    'tree_method':'gpu_hist',\n",
    "        'enable_categorical':True\n",
    "} \n",
    "\n",
    "all_models=[]\n",
    "for i in [1200, 54,55]:\n",
    "    param[\"random_state\"] = i\n",
    "    model = xgb.XGBRegressor(**param)  \n",
    "    model.fit(train_labeled,target)\n",
    "    all_models.append(model)\n",
    "\n",
    "preds = [model.predict(test_sub)  for model in all_models]\n",
    "mean_preds = np.mean(preds, axis=0)\n",
    "\n",
    "\n",
    "best=pd.read_csv('/kaggle/input/bestresultgediz33/gediz_57.csv')\n",
    "best['preds']=mean_preds\n",
    "print(f'8.ay ortalama tüketim :{train[(train.year==2021) &(train.month==8)].tüketim.mean()}')\n",
    "print(f'8.ay preds ortalama tüketim:{np.mean(mean_preds)}')\n",
    "importances=model.feature_importances_\n",
    "features=test_sub.columns\n",
    "dum=pd.DataFrame(data={'features':features,'importances_rate':importances}).sort_values('importances_rate',ascending=False)\n",
    "sns.set(rc={'figure.figsize':(30,15)})\n",
    "g=sns.barplot(x=dum.features,y=dum.importances_rate)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.read_csv('/kaggle/input/gdz-elektrik-datathon-2023/sample_submission.csv')\n",
    "submission['Dağıtılan Enerji (MWh)']=mean_preds\n",
    "submission.set_index('Tarih').to_csv('/kaggle/working/gediz_57.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best['Dağıtılan Enerji (MWh)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
